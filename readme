Researcher:
Hussein Soboh (hussein.soboh@gmail.com)
Master in Applied Statistics and Data Science
Birzeit University - Ramallah - Palestine
Supervisor: Dr. Hassan Abo Hassan
Submitted on June 2020

Normality tests are very important in statistical inference; their purpose is to know if the data issampled from normal population.  The normality of the data is a prerequisite for several parametricstatistics such as t-test, ANOVA, and regression analysis.  Violation to the normality assumption mayyield to incorrect results and wrong decisions. There are many tests available to detect departure fromnormality for a random sample.  But these tests sometimes lead to contradicting results.  Moreover,some of them can be applied under certain conditions.  In this research we build a machine learningclassification  model  to  predict  the  “normality”  of  the  data  using  several  features:  size,  skewness,kurtosis, median, and percentage of data lies within 1, 2, and 3 standard deviations.  To find the bestclassification technique that fits our data, three models created using three classification techniques:Random Forest (RF), Gradient Boosting Machines (GBM), and Support Vector Machines (SVM).The evaluation phase showed high accuracy and ROCAUC for the three models with few points infavor for “RF” model.  Power comparison also executed for ”RF” model against seven statistical tests:Shapiro-Wilk (SW), Anderson-Darling (AD), Jarque-Bera (JB), Shapiro-Francia (SF), Kolmogorov-Smirnov (KS), Cramer-von Mises (CVM), and Lilliefors (Lillie).  The comparison concluded usingMonte Carlo simulation on 25 alternative distributions on different sample sizes.  The results showedsignificantly the higher power for the model comparing to the other normality tests
